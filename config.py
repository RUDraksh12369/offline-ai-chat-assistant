# config.py

MODEL_NAME = "llama3.2"

CHAT_TEMPERATURE = 0.7
CHAT_MAX_TOKENS = 2048

AUTOCOMPLETE_TEMPERATURE = 0.3
AUTOCOMPLETE_MAX_TOKENS = 10

AGENT_TEMPERATURE = 0.1
